{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse import (  DependencyGraph,   ProjectiveDependencyParser,    NonprojectiveDependencyParser)\n",
    "from nltk.parse.transitionparser import TransitionParser, Configuration, Transition\n",
    "from nltk.parse import ParserI, DependencyGraph, DependencyEvaluator\n",
    "import tempfile\n",
    "import os\n",
    "from nltk.parse import TransitionParser\n",
    "from numpy import array\n",
    "from scipy import sparse\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from os import remove\n",
    "import tempfile\n",
    "import pickle\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from pprint import pformat\n",
    "import subprocess\n",
    "import warnings\n",
    "\n",
    "from six import string_types\n",
    "\n",
    "from nltk.tree import Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDependencyGraph(object):\n",
    "    \"\"\"\n",
    "    A container for the nodes and labelled edges of a dependency structure.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tree_str=None, cell_extractor=None, zero_based=False, cell_separator=None, top_relation_label='ROOT'):\n",
    "\n",
    "        self.nodes = defaultdict(lambda:  {'address': None,\n",
    "                                           'word': None,\n",
    "                                           'lemma': None,\n",
    "                                           'ctag': None,\n",
    "                                           'tag': None,\n",
    "                                           'feats': None,\n",
    "                                           'head': None,\n",
    "                                           'deps': defaultdict(list),\n",
    "                                           'rel': None,\n",
    "                                            'misc':None,\n",
    "                                           })\n",
    "\n",
    "        self.nodes[0].update(\n",
    "            {\n",
    "                'ctag': 'TOP',\n",
    "                'tag': 'TOP',\n",
    "                'address': 0,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.root = None\n",
    "\n",
    "        if tree_str:\n",
    "            self._parse(\n",
    "                tree_str,\n",
    "                cell_extractor=cell_extractor,\n",
    "                zero_based=zero_based,\n",
    "                cell_separator=cell_separator,\n",
    "                top_relation_label=top_relation_label,\n",
    "            )\n",
    "\n",
    "    def remove_by_address(self, address):\n",
    "        \"\"\"\n",
    "        Removes the node with the given address.  References\n",
    "        to this node in others will still exist.\n",
    "        \"\"\"\n",
    "        del self.nodes[address]\n",
    "\n",
    "\n",
    "    def redirect_arcs(self, originals, redirect):\n",
    "        for node in self.nodes.values():\n",
    "            new_deps = []\n",
    "            for dep in node['deps']:\n",
    "                if dep in originals:\n",
    "                    new_deps.append(redirect)\n",
    "                else:\n",
    "                    new_deps.append(dep)\n",
    "            node['deps'] = new_deps\n",
    "\n",
    "\n",
    "    def add_arc(self, head_address, mod_address):\n",
    "        relation = self.nodes[mod_address]['rel']\n",
    "        self.nodes[head_address]['deps'].setdefault(relation, [])\n",
    "        self.nodes[head_address]['deps'][relation].append(mod_address)\n",
    "\n",
    "        #self.nodes[head_address]['deps'].append(mod_address)\n",
    "\n",
    "\n",
    "    def connect_graph(self):\n",
    "\n",
    "        for node1 in self.nodes.values():\n",
    "            for node2 in self.nodes.values():\n",
    "                if node1['address'] != node2['address'] and node2['rel'] != 'TOP':\n",
    "                    relation = node2['rel']\n",
    "                    node1['deps'].setdefault(relation, [])\n",
    "                    node1['deps'][relation].append(node2['address'])\n",
    "\n",
    "                    #node1['deps'].append(node2['address'])\n",
    "\n",
    "    def get_by_address(self, node_address):\n",
    "        \"\"\"Return the node with the given address.\"\"\"\n",
    "        return self.nodes[node_address]\n",
    "\n",
    "\n",
    "    def contains_address(self, node_address):\n",
    "        return node_address in self.nodes\n",
    "\n",
    "\n",
    "    def to_dot(self):\n",
    "        # Start the digraph specification\n",
    "        s = 'digraph G{\\n'\n",
    "        s += 'edge [dir=forward]\\n'\n",
    "        s += 'node [shape=plaintext]\\n'\n",
    "\n",
    "        # Draw the remaining nodes\n",
    "        for node in sorted(self.nodes.values(), key=lambda v: v['address']):\n",
    "            s += '\\n%s [label=\"%s (%s)\"]' % (node['address'], node['address'], node['word'])\n",
    "            for rel, deps in node['deps'].items():\n",
    "                for dep in deps:\n",
    "                    if rel is not None:\n",
    "                        s += '\\n%s -> %s [label=\"%s\"]' % (node['address'], dep, rel)\n",
    "                    else:\n",
    "                        s += '\\n%s -> %s ' % (node['address'], dep)\n",
    "        s += \"\\n}\"\n",
    "\n",
    "        return s\n",
    "\n",
    "\n",
    "    def _repr_svg_(self):\n",
    "        dot_string = self.to_dot()\n",
    "\n",
    "        try:\n",
    "            process = subprocess.Popen(\n",
    "                ['dot', '-Tsvg'],\n",
    "                stdin=subprocess.PIPE,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                universal_newlines=True,\n",
    "            )\n",
    "        except OSError:\n",
    "            raise Exception('Cannot find the dot binary from Graphviz package')\n",
    "        out, err = process.communicate(dot_string)\n",
    "        if err:\n",
    "            raise Exception(\n",
    "                'Cannot create svg representation by running dot from string: {}'\n",
    "                ''.format(dot_string))\n",
    "        return out\n",
    "\n",
    "    def __str__(self):\n",
    "        return pformat(self.nodes)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<DependencyGraph with {0} nodes>\".format(len(self.nodes))\n",
    "\n",
    "    @staticmethod\n",
    "    def load(filename, zero_based=False, cell_separator=None, top_relation_label='ROOT'):\n",
    "        with open(filename) as infile:\n",
    "            return [\n",
    "                DependencyGraph(\n",
    "                    tree_str,\n",
    "                    zero_based=zero_based,\n",
    "                    cell_separator=cell_separator,\n",
    "                    top_relation_label=top_relation_label,\n",
    "                )\n",
    "                for tree_str in infile.read().split('\\n\\n')\n",
    "            ]\n",
    "\n",
    "\n",
    "    def left_children(self, node_index):\n",
    "        children = chain.from_iterable(self.nodes[node_index]['deps'].values())\n",
    "        index = self.nodes[node_index]['address']\n",
    "        return sum(1 for c in children if c < index)\n",
    "\n",
    "\n",
    "    def right_children(self, node_index):\n",
    "        children = chain.from_iterable(self.nodes[node_index]['deps'].values())\n",
    "        index = self.nodes[node_index]['address']\n",
    "        return sum(1 for c in children if c > index)\n",
    "\n",
    "\n",
    "    def add_node(self, node):\n",
    "        if not self.contains_address(node['address']):\n",
    "            self.nodes[node['address']].update(node)\n",
    "\n",
    "\n",
    "    def _parse(self, input_, cell_extractor=None, zero_based=False, cell_separator=None, top_relation_label='ROOT'):\n",
    "        \"\"\"Parse a sentence.\n",
    "\n",
    "        :param extractor: a function that given a tuple of cells returns a\n",
    "        7-tuple, where the values are ``word, lemma, ctag, tag, feats, head,\n",
    "        rel``.\n",
    "\n",
    "        :param str cell_separator: the cell separator. If not provided, cells\n",
    "        are split by whitespace.\n",
    "\n",
    "        :param str top_relation_label: the label by which the top relation is\n",
    "        identified, for examlple, `ROOT`, `null` or `TOP`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def extract_3_cells(cells, index):\n",
    "            word, tag, head = cells\n",
    "            return index, word, word, tag, tag, '', head, ''\n",
    "\n",
    "        def extract_4_cells(cells, index):\n",
    "            word, tag, head, rel = cells\n",
    "            return index, word, word, tag, tag, '', head, rel\n",
    "\n",
    "        def extract_7_cells(cells, index):\n",
    "            line_index, word, lemma, tag, _, head, rel = cells\n",
    "            try:\n",
    "                index = int(line_index)\n",
    "            except ValueError:\n",
    "                # index can't be parsed as an integer, use default\n",
    "                pass\n",
    "            return index, word, lemma, tag, tag, '', head, rel\n",
    "\n",
    "        def extract_10_cells(cells, index):\n",
    "            line_index, word, lemma, ctag, tag, feats, head, rel, _, misc= cells\n",
    "            try:\n",
    "                index = int(line_index)\n",
    "            except ValueError:\n",
    "                # index can't be parsed as an integer, use default\n",
    "                pass\n",
    "            return index, word, lemma, ctag, tag, feats, head, rel,misc\n",
    "\n",
    "        extractors = {\n",
    "            3: extract_3_cells,\n",
    "            4: extract_4_cells,\n",
    "            7: extract_7_cells,\n",
    "            10: extract_10_cells,\n",
    "        }\n",
    "\n",
    "        if isinstance(input_, string_types):\n",
    "            input_ = (line for line in input_.split('\\n'))\n",
    "\n",
    "        lines = (l.rstrip() for l in input_)\n",
    "        lines = (l for l in lines if l)\n",
    "\n",
    "        cell_number = None\n",
    "        for index, line in enumerate(lines, start=1):\n",
    "            cells = line.split(cell_separator)\n",
    "            if cell_number is None:\n",
    "                cell_number = len(cells)\n",
    "            else:\n",
    "                assert cell_number == len(cells)\n",
    "\n",
    "            if cell_extractor is None:\n",
    "                try:\n",
    "                    cell_extractor = extractors[cell_number]\n",
    "                except KeyError:\n",
    "                    raise ValueError(\n",
    "                        'Number of tab-delimited fields ({0}) not supported by '\n",
    "                        'CoNLL(10) or Malt-Tab(4) format'.format(cell_number)\n",
    "                    )\n",
    "\n",
    "            try:\n",
    "                index, word, lemma, ctag, tag, feats, head, rel, misc = cell_extractor(cells, index)\n",
    "            except (TypeError, ValueError):\n",
    "                # cell_extractor doesn't take 2 arguments or doesn't return 8\n",
    "                # values; assume the cell_extractor is an older external\n",
    "                # extractor and doesn't accept or return an index.\n",
    "                word, lemma, ctag, tag, feats, head, rel = cell_extractor(cells)\n",
    "\n",
    "            if head == '_':\n",
    "                continue\n",
    "\n",
    "            head = int(head)\n",
    "            if zero_based:\n",
    "                head += 1\n",
    "\n",
    "            self.nodes[index].update(\n",
    "                {\n",
    "                    'address': index,\n",
    "                    'word': word,\n",
    "                    'lemma': lemma,\n",
    "                    'ctag': ctag,\n",
    "                    'tag': tag,\n",
    "                    'feats': feats,\n",
    "                    'head': head,\n",
    "                    'rel': rel,\n",
    "                    'misc':misc\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Make sure that the fake root node has labeled dependencies.\n",
    "            if (cell_number == 3) and (head == 0):\n",
    "                rel = top_relation_label\n",
    "            self.nodes[head]['deps'][rel].append(index)\n",
    "\n",
    "        if self.nodes[0]['deps'][top_relation_label]:\n",
    "            root_address = self.nodes[0]['deps'][top_relation_label][0]\n",
    "            self.root = self.nodes[root_address]\n",
    "            self.top_relation_label = top_relation_label\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                \"The graph doesn't contain a node \"\n",
    "                \"that depends on the root element.\"\n",
    "            )\n",
    "\n",
    "    def _word(self, node, filter=True):\n",
    "        w = node['word']\n",
    "        if filter:\n",
    "            if w != ',':\n",
    "                return w\n",
    "        return w\n",
    "\n",
    "    def _tree(self, i):\n",
    "        \"\"\" Turn dependency graphs into NLTK trees.\n",
    "\n",
    "        :param int i: index of a node\n",
    "        :return: either a word (if the indexed node is a leaf) or a ``Tree``.\n",
    "        \"\"\"\n",
    "        node = self.get_by_address(i)\n",
    "        word = node['word']\n",
    "        deps = sorted(chain.from_iterable(node['deps'].values()))\n",
    "\n",
    "        if deps:\n",
    "            return Tree(word, [self._tree(dep) for dep in deps])\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "    def tree(self):\n",
    "        \"\"\"\n",
    "        Starting with the ``root`` node, build a dependency tree using the NLTK\n",
    "        ``Tree`` constructor. Dependency labels are omitted.\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "\n",
    "        word = node['word']\n",
    "        deps = sorted(chain.from_iterable(node['deps'].values()))\n",
    "        return Tree(word, [self._tree(dep) for dep in deps])\n",
    "\n",
    "\n",
    "    def triples(self, node=None):\n",
    "        \"\"\"\n",
    "        Extract dependency triples of the form:\n",
    "        ((head word, head tag), rel, (dep word, dep tag))\n",
    "        \"\"\"\n",
    "\n",
    "        if not node:\n",
    "            node = self.root\n",
    "\n",
    "        head = (node['word'], node['ctag'])\n",
    "        for i in sorted(chain.from_iterable(node['deps'].values())):\n",
    "            dep = self.get_by_address(i)\n",
    "            yield (head, dep['rel'], (dep['word'], dep['ctag']))\n",
    "            for triple in self.triples(node=dep):\n",
    "                yield triple\n",
    "\n",
    "\n",
    "    def _hd(self, i):\n",
    "        try:\n",
    "            return self.nodes[i]['head']\n",
    "        except IndexError:\n",
    "            return None\n",
    "\n",
    "    def _rel(self, i):\n",
    "        try:\n",
    "            return self.nodes[i]['rel']\n",
    "        except IndexError:\n",
    "            return None\n",
    "\n",
    "    # what's the return type?  Boolean or list?\n",
    "    def contains_cycle(self):\n",
    "        \"\"\"Check whether there are cycles.\n",
    "\n",
    "        >>> dg = DependencyGraph(treebank_data)\n",
    "        >>> dg.contains_cycle()\n",
    "        False\n",
    "\n",
    "        >>> cyclic_dg = DependencyGraph()\n",
    "        >>> top = {'word': None, 'deps': [1], 'rel': 'TOP', 'address': 0}\n",
    "        >>> child1 = {'word': None, 'deps': [2], 'rel': 'NTOP', 'address': 1}\n",
    "        >>> child2 = {'word': None, 'deps': [4], 'rel': 'NTOP', 'address': 2}\n",
    "        >>> child3 = {'word': None, 'deps': [1], 'rel': 'NTOP', 'address': 3}\n",
    "        >>> child4 = {'word': None, 'deps': [3], 'rel': 'NTOP', 'address': 4}\n",
    "        >>> cyclic_dg.nodes = {\n",
    "        ...     0: top,\n",
    "        ...     1: child1,\n",
    "        ...     2: child2,\n",
    "        ...     3: child3,\n",
    "        ...     4: child4,\n",
    "        ... }\n",
    "        >>> cyclic_dg.root = top\n",
    "\n",
    "        >>> cyclic_dg.contains_cycle()\n",
    "        [3, 1, 2, 4]\n",
    "\n",
    "        \"\"\"\n",
    "        distances = {}\n",
    "\n",
    "        for node in self.nodes.values():\n",
    "            for dep in node['deps']:\n",
    "                key = tuple([node['address'], dep])\n",
    "                distances[key] = 1\n",
    "\n",
    "        for _ in self.nodes:\n",
    "            new_entries = {}\n",
    "\n",
    "            for pair1 in distances:\n",
    "                for pair2 in distances:\n",
    "                    if pair1[1] == pair2[0]:\n",
    "                        key = tuple([pair1[0], pair2[1]])\n",
    "                        new_entries[key] = distances[pair1] + distances[pair2]\n",
    "\n",
    "            for pair in new_entries:\n",
    "                distances[pair] = new_entries[pair]\n",
    "                if pair[0] == pair[1]:\n",
    "                    path = self.get_cycle_path(self.get_by_address(pair[0]), pair[0])\n",
    "                    return path\n",
    "\n",
    "        return False  # return []?\n",
    "\n",
    "\n",
    "    def get_cycle_path(self, curr_node, goal_node_index):\n",
    "        for dep in curr_node['deps']:\n",
    "            if dep == goal_node_index:\n",
    "                return [curr_node['address']]\n",
    "        for dep in curr_node['deps']:\n",
    "            path = self.get_cycle_path(self.get_by_address(dep), goal_node_index)\n",
    "            if len(path) > 0:\n",
    "                path.insert(0, curr_node['address'])\n",
    "                return path\n",
    "        return []\n",
    "\n",
    "\n",
    "    def to_conll(self, style):\n",
    "        \"\"\"\n",
    "        The dependency graph in CoNLL format.\n",
    "\n",
    "        :param style: the style to use for the format (3, 4, 10 columns)\n",
    "        :type style: int\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "\n",
    "        if style == 3:\n",
    "            template = '{word}\\t{tag}\\t{head}\\n'\n",
    "        elif style == 4:\n",
    "            template = '{word}\\t{tag}\\t{head}\\t{rel}\\n'\n",
    "        elif style == 10:\n",
    "            template = '{i}\\t{word}\\t{lemma}\\t{ctag}\\t{tag}\\t{feats}\\t{head}\\t{rel}\\t_\\t{misc}\\n'\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Number of tab-delimited fields ({0}) not supported by '\n",
    "                'CoNLL(10) or Malt-Tab(4) format'.format(style)\n",
    "            )\n",
    "\n",
    "        return ''.join(template.format(i=i, **node) for i, node in sorted(self.nodes.items()) if node['tag'] != 'TOP')\n",
    "\n",
    "\n",
    "    def nx_graph(self):\n",
    "        \"\"\"Convert the data in a ``nodelist`` into a networkx labeled directed graph.\"\"\"\n",
    "        import networkx\n",
    "\n",
    "        nx_nodelist = list(range(1, len(self.nodes)))\n",
    "        nx_edgelist = [\n",
    "            (n, self._hd(n), self._rel(n))\n",
    "            for n in nx_nodelist if self._hd(n)\n",
    "        ]\n",
    "        self.nx_labels = {}\n",
    "        for n in nx_nodelist:\n",
    "            self.nx_labels[n] = self.nodes[n]['word']\n",
    "\n",
    "        g = networkx.MultiDiGraph()\n",
    "        g.add_nodes_from(nx_nodelist)\n",
    "        g.add_edges_from(nx_edgelist)\n",
    "\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(parser, depgraphs, modelfile, verbose=True):\n",
    "\n",
    "    try:\n",
    "        input_file = tempfile.NamedTemporaryFile(prefix='transition_parse.train',dir=tempfile.gettempdir(), delete=False)\n",
    "\n",
    "        if parser._algorithm == parser.ARC_STANDARD:\n",
    "            parser._create_training_examples_arc_std(depgraphs, input_file)\n",
    "        else:\n",
    "            parser._create_training_examples_arc_eager(depgraphs, input_file)\n",
    "\n",
    "        input_file.close()\n",
    "        # Using the temporary file to train the libsvm classifier\n",
    "        x_train, y_train = load_svmlight_file(input_file.name)\n",
    "        model = MLPClassifier(solver='lbfgs', alpha=1e-3,hidden_layer_sizes=52, random_state=1, verbose=verbose)\n",
    "        '''model = svm.SVC(kernel='poly',degree=2, coef0=0,gamma=0.2,C=0.5,verbose=verbose,probability=True)\n",
    "        '''\n",
    "        model.fit(x_train, y_train)\n",
    "        # Save the model to file name (as pickle)\n",
    "        pickle.dump(model, open(modelfile, 'wb'))\n",
    "    finally:\n",
    "        remove(input_file.name)\n",
    "        return modelfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ca_ancora-ud-test.conllu', 'r') as f:\n",
    "    graphs = [myDependencyGraph(entry, top_relation_label='root') for entry in f.read().split('\\n\\n') if entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp.arcstd.model'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_arc_std = TransitionParser('arc-standard')\n",
    "train_model(parser_arc_std,graphs,'temp.arcstd.model',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ca_ancora-ud-test.conllu', 'r') as f:\n",
    "    graphst = [DependencyGraph(entry, top_relation_label='root') for entry in f.read().split('\\n\\n') if entry]\n",
    "\n",
    "result = parser_arc_std.parse(graphst, 'temp.arcstd.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = DependencyEvaluator(result,graphst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7112622826908541, 0.8208616780045351)\n"
     ]
    }
   ],
   "source": [
    "print(de.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
