{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import nltk, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "        Data Loading TRAIN:\n",
    "        ----------\n",
    "        The data is loaded from a tsv file\n",
    "        ---------\n",
    "\n",
    "        Creating Sentences: \n",
    "        ----------\n",
    "        For tags the sentences are created using \" 。\" to define end of a sentence\n",
    "        ----------\n",
    "'''\n",
    "whole_text = []\n",
    "\n",
    "def tagSetupTrain(): \n",
    "  testfile = open('train.tsv', 'r')\n",
    "  sentence = []\n",
    "  for line in testfile:\n",
    "    pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    if pieces[0]=='。':\n",
    "      whole_text.append((sentence))\n",
    "      sentence = []\n",
    "    else:\n",
    "      sentence.append(tuple(pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagSetupTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179491"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "        Data Loading TEST:\n",
    "        ----------\n",
    "        The data is loaded from a tsv file\n",
    "        ---------\n",
    "\n",
    "        Creating Sentences: \n",
    "        ----------\n",
    "        For tags the sentences are created using \" 。\" to define end of a sentence\n",
    "        ----------\n",
    "'''\n",
    "whole_test_text = []\n",
    "\n",
    "testfile = open('test.tsv', 'r')\n",
    "sentence_test = []\n",
    "for line in testfile:\n",
    "    pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    if pieces[0]=='。':\n",
    "      whole_test_text.append((sentence_test))\n",
    "      sentence_test = []\n",
    "    else:\n",
    "      sentence_test.append(tuple(pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set = whole_text, whole_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Training Set Length - 179491\n",
      "Testing Set Length - 3351\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training Data Glimpse -\n",
      "\n",
      "[[('時', '0'), ('間', '1'), ('：', '1'), ('三', '0'), ('月', '1'), ('十', '0'), ('日', '1'), ('（', '1'), ('星', '0'), ('期', '0'), ('四', '1'), ('）', '1'), ('上', '0'), ('午', '1'), ('十', '0'), ('時', '1')]]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 100)\n",
    "print(\"Training Set Length -\", len(train_set))\n",
    "print(\"Testing Set Length -\", len(test_set))\n",
    "print(\"-\" * 100)\n",
    "print(\"Training Data Glimpse -\\n\")\n",
    "print(train_set[:1])\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8188676\n",
      "194345\n"
     ]
    }
   ],
   "source": [
    "# create list of train and test tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('間', '1'), ('：', '1'), ('三', '0'), ('月', '1')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some of the tagged words.\n",
    "train_tagged_words[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'0', '1'}\n"
     ]
    }
   ],
   "source": [
    "# let's check how many unique tags are present in training data\n",
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6115\n"
     ]
    }
   ],
   "source": [
    "# let's check how many words are present in vocabulary\n",
    "vocab = {word for word,tag in train_tagged_words}\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute emission probability for a given word for a given tag\n",
    "def word_given_tag(word,tag,train_bag= train_tagged_words):\n",
    "    \"\"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        word: individualw word w\n",
    "        train_bag: it is the training set that we initialized at top.\n",
    "        \n",
    "        What the function does?\n",
    "        -----------------------\n",
    "        It computes emission probabilties for a given word.\n",
    "        \n",
    "    \"\"\"\n",
    "    taglist = [pair for pair in train_bag if pair[1] == tag]\n",
    "    tag_count = len(taglist)    \n",
    "    w_in_tag = [pair[0] for pair in taglist if pair[0]==word]    \n",
    "    word_count_given_tag = len(w_in_tag)    \n",
    "    \n",
    "    return (word_count_given_tag,tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute transition probabilities of a previous and next tag\n",
    "def t2_given_t1(t2,t1,train_bag=train_tagged_words):\n",
    "    \"\"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        t2: tag\n",
    "        t1: tag\n",
    "        train_bag: it is the training set that we initialized at top.\n",
    "        \n",
    "        What the function does?\n",
    "        -----------------------\n",
    "        It ompute transition probabilities of a previous and next tag\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    t1_tags = [tag for tag in tags if tag==t1]\n",
    "    count_of_t1 = len(t1_tags)\n",
    "    t2_given_t1 = [tags[index+1] for index in range(len(tags)-1) if tags[index] == t1 and tags[index+1] == t2]\n",
    "    count_t2_given_t1 = len(t2_given_t1)\n",
    "    return(count_t2_given_t1,count_of_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.159006</td>\n",
       "      <td>0.840994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.465715</td>\n",
       "      <td>0.534285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.159006  0.840994\n",
       "1  0.465715  0.534285"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "\n",
    "# dataset glimpse\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's test our Viterbi algorithm on the sample sentences of test dataset. We are using sample senetences to minimize server crash\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = 0\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]\n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_seq_v1 = Viterbi_1(test_tagged_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi_1 Accuracy:  75.80645161290323\n"
     ]
    }
   ],
   "source": [
    "check_v1 = [i for i, j in zip(tagged_seq_v1, test_run_base) if i == j] \n",
    "accuracy_v1 = len(check_v1)/len(tagged_seq_v1)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy_v1*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69       100\n",
      "           1       0.78      0.82      0.80       148\n",
      "\n",
      "    accuracy                           0.76       248\n",
      "   macro avg       0.75      0.74      0.75       248\n",
      "weighted avg       0.76      0.76      0.76       248\n",
      "\n",
      "[[ 66  34]\n",
      " [ 26 122]]\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "true = []\n",
    "for i, j in (tagged_seq_v1):\n",
    "#     print(j)\n",
    "    pred.append(j)\n",
    "for i, j in (test_run_base):\n",
    "#     print(j)\n",
    "    true.append(j)\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(true,pred, target_names=target_names))\n",
    "print(confusion_matrix(true, pred, labels=[\"0\", \"1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Fetch abalone dataset from mldata.org\n",
    "data = whole_text\n",
    "preprocessing_pipe = make_pipeline(\n",
    "    OneHotEncoder(categorical_features=[0], sparse=False),\n",
    "    #Scale all from 0 to 1\n",
    "    MinMaxScaler())\n",
    "# Apply preprocessing pipe to dataset and store the dataset in dict.\n",
    "X = ct.fit_transform(X)\n",
    "# datasets[\"chinese\"] = {\n",
    "#     \"X\": preprocessing_pipe.fit_transform(data[0]),\n",
    "#     \"y\": data[1]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Class that only holds a collection of different \n",
    "# base classifiers for usage with SSL methods.\n",
    "class base_classifiers:\n",
    "    KNN = KNeighborsClassifier(\n",
    "        n_neighbors=3,\n",
    "        metric=\"euclidean\",\n",
    "        n_jobs=2  # Parallelize work on CPUs\n",
    "    )\n",
    "    NB = GaussianNB(\n",
    "        priors=None\n",
    "    )\n",
    "    #SVM = SVC(\n",
    "    #    C=1.0,\n",
    "    #    kernel='poly',\n",
    "    #    degree=1,\n",
    "    #    tol=0.001,\n",
    "    #)\n",
    "    CART = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        # splitter='best',\n",
    "        # max_depth=None,\n",
    "        # min_samples_split=2,\n",
    "        min_samples_leaf=2,\n",
    "        # min_weight_fraction_leaf=0.0,\n",
    "        # max_features=None,\n",
    "        # random_state=None,\n",
    "        # max_leaf_nodes=None,\n",
    "        # min_impurity_split=1e-07,\n",
    "        # class_weight=None,\n",
    "        # presort=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from standard_self_training import StandardSelfTraining\n",
    "from tri_training import TriTraining\n",
    "\n",
    "# All classifiers used for testing\n",
    "classifiers = [\n",
    "\n",
    "    TriTraining(\"TriTraining (CART)\", base_classifiers.CART),\n",
    "    StandardSelfTraining(\"Self-Training (CART)\", base_classifiers.CART)\n",
    "]\n",
    "labeling_rates = [0.10, 0.20, 0.30, 0.40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def _training_scoring_iteration(clf, X, y, training_index, test_index, labeling_rate):\n",
    "    \"\"\" \n",
    "    One iteration of fully training and scoring a \n",
    "    classifier on given data (one Kfold split)\n",
    "    \"\"\"\n",
    "    #Testing set is set aside.. - 1/10th of the data\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "    #For generating a testing and transductive set\n",
    "    split_data = train_test_split(\n",
    "        X[training_index],\n",
    "        y[training_index],\n",
    "        test_size=labeling_rate,\n",
    "        random_state=42\n",
    "    )\n",
    "    (X_unlabeled, X_labeled, y_unlabeled, y_labeled) = split_data\n",
    "\n",
    "    #Training set - 9/10 of data\n",
    "    X_train = np.concatenate((X_labeled, X_unlabeled))\n",
    "    y_train = np.concatenate((\n",
    "        y_labeled.astype(str),\n",
    "        np.full_like(y_unlabeled.astype(str), \"unlabeled\")\n",
    "    ))\n",
    "    \n",
    "    #Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #Score the classifier\n",
    "    transductive_score = clf.score(X_unlabeled, y_unlabeled.astype(str))\n",
    "    testing_score = clf.score(X_test, y_test.astype(str))\n",
    "\n",
    "    cnf_matrix = pd.DataFrame(\n",
    "        confusion_matrix(y_test.astype(str), clf.predict(X_test).astype(str))\n",
    "    )\n",
    "    \n",
    "    return transductive_score, testing_score, cnf_matrix\n",
    "    \n",
    "def train_and_score(clf, X, y, cv, labeling_rate):\n",
    "    \"\"\"\n",
    "    Perform KFold cross-validation of a classifier on a given data\n",
    "    and labelling rate\n",
    "    \"\"\"\n",
    "    transductive_scores = []\n",
    "    testing_scores = []\n",
    "    for training_index, test_index in cv.split(X,y):\n",
    "        transductive_score, testing_score, cnf_matrix = _training_scoring_iteration(clf, X, y, training_index, test_index, labeling_rate)\n",
    "        \n",
    "        transductive_scores.append(transductive_score)\n",
    "        testing_scores.append(testing_score)\n",
    "        print(\"#\", end=\"\")\n",
    "    print()\n",
    "    scores = {\n",
    "        \"trans_mean\": np.mean(transductive_scores),\n",
    "        \"test_mean\": np.mean(testing_scores),\n",
    "        \"trans_std\": np.std(transductive_scores),\n",
    "        \"test_std\": np.std(testing_scores)\n",
    "    }\n",
    "    return scores, cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\" \n",
    "The main loop for testing \n",
    "all classifiers with \n",
    "all datasets and \n",
    "all labeling rates\n",
    "\"\"\"\n",
    "results = None\n",
    "cnf_matrixes = {}\n",
    "for classifier in classifiers:\n",
    "    cnf_matrixes[classifier.name] = {}\n",
    "    print(classifier.name)\n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        cnf_matrixes[classifier.name][dataset_name] = {}\n",
    "        print(\"dataset:\", dataset_name, \"\\t\")\n",
    "        for labeling_rate in labeling_rates:\n",
    "            print(\"rate:\", labeling_rate, end=\" \")\n",
    "\n",
    "            test_info = { \"classifier\": classifier.name, \"dataset\":dataset_name, \"labeling_rate\":labeling_rate}\n",
    "            cv = KFold(n_splits=10, random_state=42)\n",
    "            scores, cnf_matrix = train_and_score(classifier, dataset[\"X\"], dataset[\"y\"], cv, labeling_rate)\n",
    "\n",
    "            if results is None:\n",
    "                results = pd.DataFrame([{**test_info, **scores}])\n",
    "            else:\n",
    "                results.loc[len(results.index)] = {**test_info, **scores}\n",
    "            cnf_matrixes[classifier.name][dataset_name][labeling_rate] = cnf_matrix\n",
    "    print()\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_test_text = []\n",
    "\n",
    "def evaluate():\n",
    "    testfile = open('test.tsv', 'r')\n",
    "    sentence_test = []\n",
    "    for line in testfile:\n",
    "        pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        if pieces[0]=='。':\n",
    "          whole_test_text.append((sentence_test))\n",
    "          sentence_test = []\n",
    "        else:\n",
    "          sentence_test.append(tuple(pieces))\n",
    "    \n",
    "    ## Uncomment this line to use random sentences. The reason for using random sentences is to minimize\n",
    "    ## the time and server crashing\n",
    "#     test = whole_test_text[50000:55000]\n",
    "#     random.seed(1234)\n",
    "#     rndom = [random.randint(1,len(whole_test_text)) for x in range(5)]\n",
    "#     test_run = [test[i] for i in rndom]\n",
    "    test_run_base = [tup for sent in whole_test_text for tup in sent]\n",
    "    test_tagged_words = [tup[0] for sent in whole_test_text for tup in sent]\n",
    "    \n",
    "\n",
    "    tagged_seq2 = Viterbi_1(test_tagged_words)\n",
    "    pred = []\n",
    "    true = []\n",
    "    for i, j in (tagged_seq2):\n",
    "    #     print(j)\n",
    "        pred.append(j)\n",
    "    for i, j in (test_run_base):\n",
    "    #     print(j)\n",
    "        true.append(j)\n",
    "    target_names = ['0', '1']\n",
    "    print(classification_report(true,pred, target_names=target_names))\n",
    "    print(confusion_matrix(true, pred, labels=[\"0\", \"1\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
