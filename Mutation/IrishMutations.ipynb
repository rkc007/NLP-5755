{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2nTI_ES3_ff"
   },
   "source": [
    "# **Celtic Mutation**\n",
    "\n",
    "\n",
    "![sentiment.png](https://i.ibb.co/VCYKQ2z/nlpmod22.png)\n",
    "\n",
    "> The code here are divided in 2 parts\n",
    "\n",
    "\n",
    "*   Done from scratch\n",
    "*   Used different algorithms to compare results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*   **Scratch** \n",
    "    * We will use Viterbi Algorithm and will also try a modified version of it.\n",
    "\n",
    "*   **Anything Goes**\n",
    "    * In this we will use pre isntalled library NLTK. \n",
    "      1.   UnigramTagger\n",
    "      2.   BigramTagger\n",
    "      3.   TrigramTagger\n",
    "      4.   HiddenMarkovModelTrainer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RbsMdpIo38Tz"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import nltk, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from IPython.display import HTML, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oSDm1Fn38T5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "        Data Loading:\n",
    "        ----------\n",
    "        The data is loaded from a tsv file\n",
    "        ---------\n",
    "\n",
    "        Creating Sentences: \n",
    "        ----------\n",
    "        For tags the sentences are created using <S> to define start of a sentence\n",
    "        ----------\n",
    "'''\n",
    "whole_text = []\n",
    "\n",
    "def tagSetupTrain(): \n",
    "  testfile = open('train.tsv', 'r')\n",
    "  sentence = []\n",
    "  for line in testfile:\n",
    "    pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    if pieces[0]=='<S>':\n",
    "      whole_text.append((sentence))\n",
    "      sentence = []\n",
    "    else:\n",
    "      sentence.append(tuple(pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2LSHfNJ38T9"
   },
   "outputs": [],
   "source": [
    "tagSetupTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1H_fMPOW38UB"
   },
   "outputs": [],
   "source": [
    "# whole_text = whole_text[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjXVlWFx38UG",
    "outputId": "b96bd4dd-1b08-48f7-975a-0218655f8c0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Training Set Length - 316737\n",
      "Testing Set Length - 79185\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training Data Glimpse -\n",
      "\n",
      "[[('is', 'N'), ('féidir', 'N'), ('leis', 'N'), ('an', 'N'), ('múinteoir', 'N'), ('scileanna', 'N'), ('éisteachta', 'N'), ('an', 'N'), ('ranga', 'N'), ('a', 'N'), ('measúnú', 'S'), ('•', 'N'), ('•', 'N'), ('•', 'N'), ('nuair', 'N'), ('a', 'N'), ('bíonn', 'S'), ('teagasc', 'N'), ('foirmiúil', 'N'), ('teanga', 'N'), ('ar', 'N'), ('siúl', 'N'), ('tríd', 'N'), ('an', 'N'), ('caoi', 'U'), ('a', 'N'), ('freagraíonn', 'U'), ('an', 'N'), ('páiste', 'N'), (\"d'úsáid\", 'N'), ('spontáineach', 'N'), ('teanga', 'N'), ('teagmhasaí', 'N'), ('i', 'N'), ('rith', 'N'), ('an', 'N'), ('lá', 'N'), ('scoile', 'N'), ('a', 'N'), ('breathnú', 'S'), ('trí', 'N'), ('ceisteanna', 'S'), ('a', 'N'), ('cur', 'S'), ('ar', 'N'), ('an', 'N'), ('páiste', 'U'), ('.', 'N')]]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# split data into training and validation set in the ratio 80:20\n",
    "\n",
    "random.seed(1234)\n",
    "train_set,test_set = train_test_split(whole_text,test_size=0.2,random_state = 101)\n",
    "\n",
    "print(\"-\" * 100)\n",
    "print(\"Training Set Length -\", len(train_set))\n",
    "print(\"Testing Set Length -\", len(test_set))\n",
    "print(\"-\" * 100)\n",
    "print(\"Training Data Glimpse -\\n\")\n",
    "print(train_set[:1])\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxgHQK2i38UL",
    "outputId": "ed17f8bc-8438-4750-c468-56dd50704ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7686253\n",
      "1917825\n"
     ]
    }
   ],
   "source": [
    "# create list of train and test tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UM0sXBnb38UQ",
    "outputId": "e6826a53-83b4-44e4-bd47-192fa2fa4e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('féidir', 'N'), ('leis', 'N'), ('an', 'N'), ('múinteoir', 'N')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some of the tagged words.\n",
    "train_tagged_words[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzfUYFyH38UW",
    "outputId": "adf7bc7e-75ef-48a1-e167-051c94841e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'T', 'N', 'U', 'S', 'H'}\n"
     ]
    }
   ],
   "source": [
    "# let's check how many unique tags are present in training data\n",
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wei0pmlv38Ua",
    "outputId": "c41cb170-c09c-4936-8781-333936d68725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151011\n"
     ]
    }
   ],
   "source": [
    "# let's check how many words are present in vocabulary\n",
    "vocab = {word for word,tag in train_tagged_words}\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RpzLoirA9qg-"
   },
   "source": [
    "**POS Tagging algorithm using Hidden Markov Model (HMM)**\n",
    "\n",
    "We'll use the HMM algorithm to tag the words. Given a sequence of words to be tagged, the task is to assign the most probable tag to the word. In other words, to every word w, assign the tag t that maximises the likelihood P(t/w).\n",
    "\n",
    "\n",
    "Since P(t/w) = P(w/t). P(t) / P(w), after ignoring P(w), we have to compute P(w/t) and P(t).\n",
    "\n",
    "Now:\n",
    "\n",
    "\n",
    "\n",
    "*   **P(w/t): is the emission probability** of a given word for a given tag. This can be computed based on the fraction of given word for given tag to the total count of that tag, ie: P(w/t) = count(w, t) / count(t).\n",
    "\n",
    "\n",
    "*   **P(t): is the probability of tag (also transition probability)** , and in a tagging task, we assume that a tag will depend only on the previous tag (Markov order 1 assumption). In other words, the probability of say a tag being NN will depend only on the previous tag t(n-1). So for e.g. if t(n-1) is a JJ, then t(n) is likely to be an NN since adjectives often precede a noun (blue coat, tall building etc.).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kA16uvi38Ue"
   },
   "outputs": [],
   "source": [
    "# compute emission probability for a given word for a given tag\n",
    "def word_given_tag(word,tag,train_bag= train_tagged_words):\n",
    "    \"\"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        word: individualw word w\n",
    "        train_bag: it is the training set that we initialized at top.\n",
    "        \n",
    "        What the function does?\n",
    "        -----------------------\n",
    "        It computes emission probabilties for a given word.\n",
    "        \n",
    "    \"\"\"\n",
    "    taglist = [pair for pair in train_bag if pair[1] == tag]\n",
    "    tag_count = len(taglist)    \n",
    "    w_in_tag = [pair[0] for pair in taglist if pair[0]==word]    \n",
    "    word_count_given_tag = len(w_in_tag)    \n",
    "    \n",
    "    return (word_count_given_tag,tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMedYS_x38Ui"
   },
   "outputs": [],
   "source": [
    "# compute transition probabilities of a previous and next tag\n",
    "def t2_given_t1(t2,t1,train_bag=train_tagged_words):\n",
    "    \"\"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        t2: tag\n",
    "        t1: tag\n",
    "        train_bag: it is the training set that we initialized at top.\n",
    "        \n",
    "        What the function does?\n",
    "        -----------------------\n",
    "        It ompute transition probabilities of a previous and next tag\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    t1_tags = [tag for tag in tags if tag==t1]\n",
    "    count_of_t1 = len(t1_tags)\n",
    "    t2_given_t1 = [tags[index+1] for index in range(len(tags)-1) if tags[index] == t1 and tags[index+1] == t2]\n",
    "    count_t2_given_t1 = len(t2_given_t1)\n",
    "    return(count_t2_given_t1,count_of_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FI-Lh5wn38Um",
    "outputId": "00ed08cb-2064-43af-8e96-d03b33a35c8e"
   },
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QlOTZOv938Up",
    "outputId": "b8ed358c-6812-447e-e1ba-2ce3bf492f6e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>N</th>\n",
       "      <th>U</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.939395</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.057376</td>\n",
       "      <td>0.003014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.835945</td>\n",
       "      <td>0.039722</td>\n",
       "      <td>0.110549</td>\n",
       "      <td>0.009542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.960100</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.944772</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.052296</td>\n",
       "      <td>0.001642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.956280</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.040170</td>\n",
       "      <td>0.002476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          T         N         U         S         H\n",
       "T  0.000144  0.939395  0.000072  0.057376  0.003014\n",
       "N  0.004241  0.835945  0.039722  0.110549  0.009542\n",
       "U  0.000050  0.960100  0.000688  0.038504  0.000658\n",
       "S  0.000064  0.944772  0.001225  0.052296  0.001642\n",
       "H  0.000187  0.956280  0.000887  0.040170  0.002476"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "\n",
    "# dataset glimpse\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnOBzjnT38Ut",
    "outputId": "62ab7f04-e61d-468d-b572-273a4e73b534"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14, 8))\n",
    "# sns.heatmap(tags_df, annot = True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HawVZQUa38Uw"
   },
   "outputs": [],
   "source": [
    "# tags_frequent = tags_df[tags_df>0.5]\n",
    "# plt.figure(figsize=(14, 8))\n",
    "# sns.heatmap(tags_frequent, annot = True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCwOPnAU-Sus"
   },
   "source": [
    "Accoridng to **Viterbi Algorithm**\n",
    "\n",
    "\n",
    "\n",
    "1.   Given a sequence of words\n",
    "2.   iterate through the sequence\n",
    "3.    for each word (starting from first word in sequence) calculate the product of emission probabilties and transition probabilties for all possible tags.\n",
    "4. assign the tag which has maximum probability obtained in step 3 above.\n",
    "5. move to the next word in sequence to repeat steps 3 and 4 above.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xAnRAky738U0"
   },
   "outputs": [],
   "source": [
    "# Vanilla Viterbi Algorithm\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    \n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = 0\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yj7W-SZK38U4"
   },
   "outputs": [],
   "source": [
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2P_oW0Hq38U7",
    "outputId": "c6d38e1b-f81e-4b0e-80b7-afed7649daeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Viterbi Algorithm Accuracy:  88.110189451862\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Vanilla Viterbi Algorithm Accuracy: ',accuracy*100)\n",
    "acc_1 = accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-eRhXYfK38VA",
    "outputId": "0c590fed-ea75-47bc-bde7-e99d5bd9272d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('gaoth', 'T'), ('gaoth', 'N')),\n",
       " (('tí', 'U'), ('tí', 'N')),\n",
       " (('freagra', 'N'), ('freagra', 'S')),\n",
       " (('aye', 'N'), ('aye', 'H')),\n",
       " (('boente', 'T'), ('boente', 'N')),\n",
       " (('aye', 'N'), ('aye', 'H')),\n",
       " (('troid', 'N'), ('troid', 'S')),\n",
       " (('diaidh', 'U'), ('diaidh', 'S')),\n",
       " (('tar', 'N'), ('tar', 'S')),\n",
       " (('cóta', 'N'), ('cóta', 'S')),\n",
       " (('craoladh', 'N'), ('craoladh', 'S')),\n",
       " (('tar', 'N'), ('tar', 'S')),\n",
       " (('creata', 'S'), ('creata', 'N')),\n",
       " (('giuirléidí', 'N'), ('giuirléidí', 'S')),\n",
       " (('aistriú', 'N'), ('aistriú', 'U')),\n",
       " (('tar', 'N'), ('tar', 'S'))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVeiXMQQ_Eoh"
   },
   "source": [
    "**Viterbi Version 2**\n",
    "\n",
    "Use transition probability of tags when emission probability is zero (in case of unknown words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F0HrRZr238VE"
   },
   "outputs": [],
   "source": [
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = 0\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]\n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YC9HuWgf38VI",
    "outputId": "1f012a75-8587-41cd-81ae-6fe2226486d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi_1 Accuracy:  89.1891891891892\n"
     ]
    }
   ],
   "source": [
    "tagged_seq_v1 = Viterbi_1(test_tagged_words)\n",
    "\n",
    "\n",
    "# accuracy\n",
    "check_v1 = [i for i, j in zip(tagged_seq_v1, test_run_base) if i == j] \n",
    "accuracy_v1 = len(check_v1)/len(tagged_seq_v1)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy_v1*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IfdROv7_zfI"
   },
   "source": [
    "**Adding Tag occurance probability weights**\n",
    "\n",
    " we will apply weights based on the probability of tag occurance to the transition probabilities of tags and then use the resulting probability for predicting unknown words.\n",
    "\n",
    "This scheme will also take into account that some POS tags are more likely to occur as compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_km4lVn38VM",
    "outputId": "b20a4c32-40ef-455c-c24c-2b6bae7d43d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T', 0.003625823922267456),\n",
       " ('N', 0.85258616909956),\n",
       " ('U', 0.034022039087185915),\n",
       " ('S', 0.10140988073122235),\n",
       " ('H', 0.008356087159764321)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a list containing tuples of POS tags and POS tag occurance probability, based on training data\n",
    "tag_prob = []\n",
    "total_tag = len([tag for word,tag in train_tagged_words])\n",
    "for t in tags:\n",
    "    each_tag = [tag for word,tag in train_tagged_words if tag==t]\n",
    "    tag_prob.append((t,len(each_tag)/total_tag))\n",
    "\n",
    "tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eM8LV9138VP"
   },
   "outputs": [],
   "source": [
    "def Viterbi_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "       \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = 0\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p             \n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use weighted transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]                 \n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSSwD1Bq38VS",
    "outputId": "c3c11714-b2a3-472d-d424-91e15207b671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi_1 Accuracy:  89.1891891891892\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tagged_seq_v2 = Viterbi_2(test_tagged_words)\n",
    "\n",
    "\n",
    "# accuracy\n",
    "check_v2 = [i for i, j in zip(tagged_seq_v2, test_run_base) if i == j] \n",
    "accuracy_v2 = len(check)/len(tagged_seq_v2)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy_v2*100)\n",
    "acc_2 = accuracy_v2*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ei6L5mZW38VX",
    "outputId": "80733362-f37f-449b-a0fe-0a4e912affbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('gaoth', 'T'), ('gaoth', 'N')),\n",
       " (('tí', 'U'), ('tí', 'N')),\n",
       " (('freagra', 'N'), ('freagra', 'S')),\n",
       " (('aye', 'N'), ('aye', 'H')),\n",
       " (('aye', 'N'), ('aye', 'H')),\n",
       " (('troid', 'N'), ('troid', 'S')),\n",
       " (('diaidh', 'U'), ('diaidh', 'S')),\n",
       " (('tar', 'N'), ('tar', 'S')),\n",
       " (('cóta', 'N'), ('cóta', 'S')),\n",
       " (('craoladh', 'N'), ('craoladh', 'S')),\n",
       " (('tar', 'N'), ('tar', 'S')),\n",
       " (('creata', 'S'), ('creata', 'N')),\n",
       " (('giuirléidí', 'N'), ('giuirléidí', 'S')),\n",
       " (('aistriú', 'N'), ('aistriú', 'U')),\n",
       " (('tar', 'N'), ('tar', 'S'))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq_v2, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHRCKnZQAAsI"
   },
   "source": [
    "# **Anything Goes**\n",
    "\n",
    "* In this we will use pre isntalled library NLTK. \n",
    "      1.   UnigramTagger\n",
    "      2.   BigramTagger\n",
    "      3.   TrigramTagger\n",
    "      4.   HiddenMarkovModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVaYZde838Vi"
   },
   "outputs": [],
   "source": [
    "import nltk   #import required libraries\n",
    "from nltk.tag import hmm\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus.reader import TaggedCorpusReader \n",
    "from nltk.corpus.reader import PlaintextCorpusReader\n",
    "from sklearn import metrics  #for evaluation purposes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FyOluve38Vl"
   },
   "outputs": [],
   "source": [
    "textAuto = []\n",
    "tagdT = []\n",
    "def tagAlign(): \n",
    "  testfile = open('train.tsv', 'r')\n",
    "  sentS = []\n",
    "  for line in testfile:\n",
    "#     total += 1\n",
    "    pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    if pieces[0]=='<S>':\n",
    "      textAuto.append((sentS))\n",
    "      sentS = []\n",
    "    else:\n",
    "      sentS.append(tuple(pieces))\n",
    "      tagdT.append(tuple(pieces))\n",
    "\n",
    "tagAlign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJhpNueX38Vo",
    "outputId": "8abe4614-0fce-436a-a939-c44d020c8a9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N', 8188100), ('S', 973469), ('U', 327110), ('H', 80504), ('T', 34895)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequency distribution of tags in our data\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in tagdT)\n",
    "tag_fd.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGjTcmFy38Vr",
    "outputId": "a6c73b85-38c1-4a29-9fd7-c636e1b2c69a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356329"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide the data into train and dev set with ratio of split = 10%\n",
    "split = int(len(whole_text) * 0.9)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3E4F79SH38Vv"
   },
   "outputs": [],
   "source": [
    "train_sents = whole_text[:split]\n",
    "dev_sents = whole_text[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy_KUuzr38Vx",
    "outputId": "da1968eb-532d-4dec-ec95-0a20f71faf68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram accuracy: 89.54418361352649\n"
     ]
    }
   ],
   "source": [
    "#Training and testing unigram tagger\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents)  \n",
    "acc_3 = unigram_tagger.evaluate(dev_sents)*100\n",
    "print(\"Unigram accuracy:\", acc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2K5jbiz38V0",
    "outputId": "0afbd6f5-5fe4-48cb-9d64-fcf5e70c4597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram accuracy: 89.88543874325117\n",
      "Trigram accuracy: 89.96265705727647\n"
     ]
    }
   ],
   "source": [
    "#Using backoff tagger for bi-tri tagger\n",
    "bigram_tagger = nltk.BigramTagger(train_sents, backoff=unigram_tagger)  \n",
    "acc_4 = bigram_tagger.evaluate(dev_sents)*100\n",
    "print(\"Bigram accuracy:\",acc_4)\n",
    "\n",
    "\n",
    "trigram_tagger = nltk.TrigramTagger(train_sents, backoff=bigram_tagger)\n",
    "acc_5 = trigram_tagger.evaluate(dev_sents)*100\n",
    "print(\"Trigram accuracy:\",acc_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aGTZm9g38V2",
    "outputId": "9b22d453-3ca3-4e5a-816e-2b31777a3a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM train accuracy: 91.26658395451258\n",
      "HMM dev accuracy: 89.99008236553826\n"
     ]
    }
   ],
   "source": [
    "Training and tagging HMM using nltk trainer\n",
    "hmm_trainer = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_tagger = hmm_trainer.train_supervised(train_sents)\n",
    "print(\"HMM train accuracy:\", hmm_tagger.evaluate(train_sents)*100)\n",
    "acc_6 = hmm_tagger.evaluate(dev_sents)*100\n",
    "print(\"HMM dev accuracy:\", acc_6)\n",
    "\n",
    "# print(\"HMM train accuracy:\", '91.26658395451258')\n",
    "# print(\"HMM dev accuracy:\", '89.99008236553826')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><h4>Viterbi V1 :</h4><td><td><h4>88.11018945186245</h4><td></tr><tr><td><h4>Viterbi V2 : </h4><td><td><h4>89.18918918918925</h4><td></tr><tr><td><h4>UnigramTagger :</h4><td><td><h4>89.54418361352649</h4><td></tr><tr><td><h4>BigramTagger :</h4><td><td><h4>89.88543874325117</h4><td></tr><tr><td><h4>TrigramTagger :</h4><td><td><h4>89.96265705727647</h4><td></tr><tr><td><h4>HiddenMarkovModelTrainer :</h4><td><td><h4>89.99008236553826</h4><td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Printing everything\n",
    "def display_table(data):\n",
    "    html = \"<table>\"\n",
    "    for row in data:\n",
    "        html += \"<tr>\"\n",
    "        for field in row:\n",
    "            html += \"<td><h4>%s</h4><td>\"%(field)\n",
    "        html += \"</tr>\"\n",
    "    html += \"</table>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "data = [['Viterbi V1 :',acc_1],['Viterbi V2 : ',acc_2],['UnigramTagger :',acc_3],['BigramTagger :',acc_4],['TrigramTagger :',acc_5],['HiddenMarkovModelTrainer :',acc_6]]\n",
    "display_table(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nq6DRqNAAa6t"
   },
   "source": [
    "**To test new data just replace the file path and rest will work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnVUemAC38V7"
   },
   "outputs": [],
   "source": [
    "whole_test_text = []\n",
    "\n",
    "def evaluate():\n",
    "    testfile = open('train.tsv', 'r')\n",
    "    sentence_test = []\n",
    "    for line in testfile:\n",
    "        pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        if pieces[0]=='<S>':\n",
    "          whole_test_text.append((sentence_test))\n",
    "          sentence_test = []\n",
    "        else:\n",
    "          sentence_test.append(tuple(pieces))\n",
    "    \n",
    "#     test = whole_test_text[50000:55000]\n",
    "#     random.seed(1234)\n",
    "#     rndom = [random.randint(1,len(whole_test_text)) for x in range(5)]\n",
    "#     test_run = [test[i] for i in rndom]\n",
    "    test_run_base = [tup for sent in whole_test_text for tup in sent]\n",
    "    test_tagged_words = [tup[0] for sent in whole_test_text for tup in sent]\n",
    "    \n",
    "    tagged_seq1 = Viterbi_1(test_tagged_words)\n",
    "    check1 = [i for i, j in zip(tagged_seq1, test_run_base) if i == j] \n",
    "    accuracy1 = len(check1)/len(tagged_seq1)\n",
    "    print('Modified Viterbi_1 Accuracy: ',accuracy1*100)\n",
    "    \n",
    "    tagged_seq2 = Viterbi_2(test_tagged_words)\n",
    "    check2 = [i for i, j in zip(tagged_seq2, test_run_base) if i == j] \n",
    "    accuracy2 = len(check2)/len(tagged_seq2)\n",
    "    print('Modified Viterbi_1 Accuracy: ',accuracy2*100)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAt8zPKFAZAM"
   },
   "outputs": [],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XCv82K1WApHQ"
   },
   "source": [
    "# **Acknowledgement :**\n",
    "\n",
    "\n",
    "\n",
    "*  [Dr. Kevin Scannell : Neural Models for Predicting Celtic Mutations ](https://www.aclweb.org/anthology/2020.sltu-1.1.pdf)\n",
    "*   [Medium](https://medium.com/data-science-in-your-pocket/pos-tagging-using-hidden-markov-models-hmm-viterbi-algorithm-in-nlp-mathematics-explained-d43ca89347c4)\n",
    "* [Towards Data Science](https://towardsdatascience.com/part-of-speech-tagging-with-hidden-markov-chain-models-e9fccc835c0e)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "IrishMutations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
