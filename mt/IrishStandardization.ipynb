{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import codecs\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading file\n",
    "'''\n",
    "\n",
    "def load_data(file):\n",
    "    sentence = ''\n",
    "    references = []\n",
    "    data = open(file, 'r')\n",
    "    for line in data:\n",
    "        token = line.rstrip(\"\\n\")\n",
    "        if token == '<s>':\n",
    "          sentence = ''\n",
    "        elif token == '</s>':\n",
    "          references.append(sentence)\n",
    "        else:\n",
    "          sentence += token + ' '\n",
    "    return references\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "BP is an exponential decay\n",
    "Brevity Penalty(BP) will be 1.0 when the candidate translation length\n",
    "is the same as any reference translation length\n",
    "'''\n",
    "\n",
    "def brevity_penalty(candidate, reference):\n",
    "    if candidate > reference:\n",
    "        return 1\n",
    "    else:\n",
    "        tmp = 1-float(reference)/float(candidate)\n",
    "        return math.pow(math.e, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sum of the clipped n-gram counts for all the candidate sentences\n",
    "in the corpus divide by the number of candidate n-grams\n",
    "\n",
    "return: precision value\n",
    "\"\"\"\n",
    "def modified_precision(clipped_count, candidate_length):\n",
    "    precision = float(clipped_count)/float(candidate_length)\n",
    "    return math.log(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clipped_dic(candidate_dic, reference_dic):\n",
    "    clipped_dic = {}\n",
    "    for key, value in candidate_dic.items():\n",
    "        if key in reference_dic:\n",
    "            ref_v = reference_dic[key]\n",
    "            clipped_dic[key] = min(value, ref_v)\n",
    "    return clipped_dic\n",
    "\n",
    "def get_clipped_dic_count(clipped_dic):\n",
    "    count = 0\n",
    "    for key, value in clipped_dic.items():\n",
    "        count += value\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "    Generate Ngram for each line.\n",
    "    @line: a line of words\n",
    "    @n: ngram\n",
    "    return: a dictionary of words and its counts\n",
    "\"\"\"\n",
    "\n",
    "def generate_n_gram(candidate, reference, n):\n",
    "    can_dic = {}\n",
    "    ref_dic = {}\n",
    "    can_list = candidate.split(\" \")\n",
    "    ref_list = reference.split(\" \")\n",
    "    can_len = 0\n",
    "\n",
    "    for i in range(0, len(can_list)-n+1):\n",
    "        key = \"\"\n",
    "        for j in range(0, n):\n",
    "            key += can_list[i+j]\n",
    "            key += \"/\"\n",
    "        can_len += 1\n",
    "        if key in can_dic:\n",
    "            can_dic[key] += 1\n",
    "        else:\n",
    "            can_dic[key] = 1\n",
    "\n",
    "    for i in range(0, len(ref_list)-n+1):\n",
    "        key = \"\"\n",
    "        for j in range(0,  n):\n",
    "            key += ref_list[i+j]\n",
    "            key += \"/\"\n",
    "\n",
    "        if key in ref_dic:\n",
    "            ref_dic[key] += 1\n",
    "        else:\n",
    "            ref_dic[key] = 1\n",
    "    return can_dic, ref_dic, can_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Generating n-gram for the calculation of BLEU score.\n",
    "\"\"\"\n",
    "\n",
    "def get_count(candidate, reference, n):\n",
    "    can_dic, ref_dic, can_len = generate_n_gram(candidate, reference, n)\n",
    "    can_clipped_dic = get_clipped_dic(can_dic, ref_dic)\n",
    "    can_clipped_count = get_clipped_dic_count(can_clipped_dic)\n",
    "    return can_clipped_count, can_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Individually calculating scores for all 4 grams\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def main(source, target):\n",
    "    can_len, ref_len = 0, 0\n",
    "\n",
    "    #Unigram model\n",
    "    uni_c, uni_t = 0, 0\n",
    "\n",
    "    #Bi gram model\n",
    "    bi_c, bi_t = 0, 0\n",
    "\n",
    "    #Tri gram model\n",
    "    tri_c, tri_t = 0, 0\n",
    "\n",
    "    #4 gram model\n",
    "    four_c, four_t = 0, 0\n",
    "    \n",
    "    source_data = load_data(source)\n",
    "    target_data = load_data(target)\n",
    "\n",
    "    for c_line, r_line in zip(source_data, target_data):\n",
    "        c_line = c_line.strip()\n",
    "        r_line = r_line.strip()\n",
    "        can_len += len(c_line.split(\" \"))\n",
    "        ref_len += len(r_line.split(\" \"))\n",
    "        \n",
    "        #Unigram model\n",
    "        c_c, t_c = get_count(c_line, r_line, 1)\n",
    "        uni_c += c_c\n",
    "        uni_t += t_c\n",
    "        \n",
    "        #Bi gram model\n",
    "        c_c, t_c = get_count(c_line, r_line, 2)\n",
    "        bi_c += c_c\n",
    "        bi_t += t_c\n",
    "        \n",
    "        #Tri gram model\n",
    "        c_c, t_c = get_count(c_line, r_line, 3)\n",
    "        tri_c += c_c\n",
    "        tri_t += t_c\n",
    "\n",
    "        #4 gram model\n",
    "        c_c, t_c = get_count(c_line, r_line, 4)\n",
    "        four_c += c_c\n",
    "        four_t += t_c\n",
    "        \n",
    "        \n",
    "#     Calculating precision for all 4 grams.\n",
    "#     Calculating Brevity Penalty.\n",
    "\n",
    "    uni_p = modified_precision(uni_c, uni_t)\n",
    "    bi_p = modified_precision(bi_c, bi_t)\n",
    "    tri_p = modified_precision(tri_c, tri_t)\n",
    "    four_p = modified_precision(four_c, four_t)\n",
    "    bp = brevity_penalty(can_len, ref_len)\n",
    "\n",
    "    score_uni = bp*math.exp(uni_p)\n",
    "    score_bi = bp*math.exp(bi_p)\n",
    "    score_tri = bp*math.exp(tri_p)\n",
    "    score_4 = bp*math.exp(four_p)\n",
    "    \n",
    "    return score_uni, score_bi, score_tri, score_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    source = 'train-source.txt'\n",
    "    target = 'train-target.txt'\n",
    "    \n",
    "    \n",
    "    source_test = 'test-source.txt'\n",
    "    target_test = 'test-target.txt' \n",
    "    \n",
    "    uni, bi, tri, four = main(source,target)\n",
    "    uni_t, bi_t, tri_t, four_t = main(source_test,target_test)\n",
    "    \n",
    "    print('----------------------BLEU Score Train------------------------')\n",
    "    data = [['Unigram :',uni],['Bigram : ',bi],['Trigram :',tri],['4gram :',four]]\n",
    "    display_table(data)\n",
    "    \n",
    "    print('----------------------BLEU Score Test------------------------')\n",
    "    data_t = [['Unigram :',uni_t],['Bigram : ',bi_t],['Trigram :',tri_t],['4gram :',four_t]]\n",
    "    display_table(data_t)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------BLEU Score Train------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><h4>Unigram :</h4><td><td><h4>0.7517325357522582</h4><td></tr><tr><td><h4>Bigram : </h4><td><td><h4>0.5636116001979694</h4><td></tr><tr><td><h4>Trigram :</h4><td><td><h4>0.42760825232225785</h4><td></tr><tr><td><h4>4gram :</h4><td><td><h4>0.3239967134640803</h4><td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------BLEU Score Test------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><h4>Unigram :</h4><td><td><h4>0.7743372494213215</h4><td></tr><tr><td><h4>Bigram : </h4><td><td><h4>0.5926382609489884</h4><td></tr><tr><td><h4>Trigram :</h4><td><td><h4>0.45729052017035937</h4><td></tr><tr><td><h4>4gram :</h4><td><td><h4>0.3525154545911444</h4><td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
